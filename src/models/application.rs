/*
 * Qovery API
 *
 * - Qovery is the fastest way to deploy your full-stack apps on any Cloud provider. - ℹ️ The API is stable and still in development.
 *
 * The version of the OpenAPI document: 1.0.4
 * Contact: support+api+documentation@qovery.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct Application {
    #[serde(rename = "id")]
    pub id: uuid::Uuid,
    #[serde(rename = "created_at")]
    pub created_at: String,
    #[serde(rename = "updated_at", skip_serializing_if = "Option::is_none")]
    pub updated_at: Option<String>,
    #[serde(rename = "storage", skip_serializing_if = "Option::is_none")]
    pub storage: Option<Vec<models::ServiceStorageStorageInner>>,
    #[serde(rename = "environment")]
    pub environment: models::ReferenceObject,
    #[serde(rename = "git_repository", skip_serializing_if = "Option::is_none")]
    pub git_repository: Option<models::ApplicationGitRepository>,
    /// Maximum cpu that can be allocated to the application based on organization cluster configuration. unit is millicores (m). 1000m = 1 cpu
    #[serde(rename = "maximum_cpu", skip_serializing_if = "Option::is_none")]
    pub maximum_cpu: Option<i32>,
    /// Maximum memory that can be allocated to the application based on organization cluster configuration. unit is MB. 1024 MB = 1GB
    #[serde(rename = "maximum_memory", skip_serializing_if = "Option::is_none")]
    pub maximum_memory: Option<i32>,
    #[serde(rename = "maximun_gpu", skip_serializing_if = "Option::is_none")]
    pub maximun_gpu: Option<i32>,
    /// name is case insensitive
    #[serde(rename = "name")]
    pub name: String,
    /// give a description to this application
    #[serde(rename = "description", skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,
    #[serde(rename = "build_mode", skip_serializing_if = "Option::is_none")]
    pub build_mode: Option<models::BuildModeEnum>,
    /// The path of the associated Dockerfile. Only if you are using build_mode = DOCKER
    #[serde(
        rename = "dockerfile_path",
        default,
        with = "::serde_with::rust::double_option",
        skip_serializing_if = "Option::is_none"
    )]
    pub dockerfile_path: Option<Option<String>>,
    /// unit is millicores (m). 1000m = 1 cpu
    #[serde(rename = "cpu", skip_serializing_if = "Option::is_none")]
    pub cpu: Option<i32>,
    /// unit is MB. 1024 MB = 1GB
    #[serde(rename = "memory", skip_serializing_if = "Option::is_none")]
    pub memory: Option<i32>,
    #[serde(rename = "gpu", skip_serializing_if = "Option::is_none")]
    pub gpu: Option<i32>,
    /// Minimum number of instances running. This resource auto-scale based on the CPU and Memory consumption. Note: 0 means that there is no application running.
    #[serde(
        rename = "min_running_instances",
        skip_serializing_if = "Option::is_none"
    )]
    pub min_running_instances: Option<i32>,
    /// Maximum number of instances running. This resource auto-scale based on the CPU and Memory consumption. Note: -1 means that there is no limit.
    #[serde(
        rename = "max_running_instances",
        skip_serializing_if = "Option::is_none"
    )]
    pub max_running_instances: Option<i32>,
    #[serde(rename = "healthchecks")]
    pub healthchecks: models::Healthcheck,
    /// Specify if the environment preview option is activated or not for this application.   If activated, a preview environment will be automatically cloned at each pull request.   If not specified, it takes the value of the `auto_preview` property from the associated environment.
    #[serde(rename = "auto_preview", skip_serializing_if = "Option::is_none")]
    pub auto_preview: Option<bool>,
    #[serde(rename = "ports", skip_serializing_if = "Option::is_none")]
    pub ports: Option<Vec<models::ServicePort>>,
    #[serde(rename = "arguments", skip_serializing_if = "Option::is_none")]
    pub arguments: Option<Vec<String>>,
    /// optional entrypoint when launching container
    #[serde(rename = "entrypoint", skip_serializing_if = "Option::is_none")]
    pub entrypoint: Option<String>,
    /// Specify if the application will be automatically updated after receiving a new commit.
    #[serde(rename = "auto_deploy", skip_serializing_if = "Option::is_none")]
    pub auto_deploy: Option<bool>,
    #[serde(rename = "annotations_groups", skip_serializing_if = "Option::is_none")]
    pub annotations_groups: Option<Vec<models::OrganizationAnnotationsGroupResponse>>,
    #[serde(rename = "labels_groups", skip_serializing_if = "Option::is_none")]
    pub labels_groups: Option<Vec<models::OrganizationLabelsGroupResponse>>,
    /// Icon URI representing the application.
    #[serde(rename = "icon_uri")]
    pub icon_uri: String,
    #[serde(
        rename = "service_type",
        default = "models::service_type_enum::service_type_application"
    )]
    pub service_type: models::ServiceTypeEnum,
    /// The target build stage in the Dockerfile to build
    #[serde(
        rename = "docker_target_build_stage",
        default,
        with = "::serde_with::rust::double_option",
        skip_serializing_if = "Option::is_none"
    )]
    pub docker_target_build_stage: Option<Option<String>>,
    #[serde(rename = "autoscaling", skip_serializing_if = "Option::is_none")]
    pub autoscaling: Option<models::KedaAutoscalingResponse>,
}

impl Application {
    pub fn new(
        id: uuid::Uuid,
        created_at: String,
        environment: models::ReferenceObject,
        name: String,
        healthchecks: models::Healthcheck,
        icon_uri: String,
        service_type: models::ServiceTypeEnum,
    ) -> Application {
        Application {
            id,
            created_at,
            updated_at: None,
            storage: None,
            environment,
            git_repository: None,
            maximum_cpu: None,
            maximum_memory: None,
            maximun_gpu: None,
            name,
            description: None,
            build_mode: None,
            dockerfile_path: None,
            cpu: None,
            memory: None,
            gpu: None,
            min_running_instances: None,
            max_running_instances: None,
            healthchecks,
            auto_preview: None,
            ports: None,
            arguments: None,
            entrypoint: None,
            auto_deploy: None,
            annotations_groups: None,
            labels_groups: None,
            icon_uri,
            service_type,
            docker_target_build_stage: None,
            autoscaling: None,
        }
    }
}
